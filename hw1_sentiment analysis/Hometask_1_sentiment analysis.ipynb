{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "LrdL__lCtr6M"
   },
   "source": [
    "# Оценка тональности"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "r_CzjN-StydR"
   },
   "source": [
    "**Описание задания**\n",
    "\n",
    "В рамках этого задания мы будем создавать программу, которая получая на вход отзыв, будет предсказывать, является ли отзыв положительным или отрицательным. Делать мы будем это таким образом: мы возьмём некоторое число заранее размеченных как положительные или отрицательные отзывов, выделим те слова, которые встречаются только в положительных или только в отрицательных отзывах, и будем считать, каких слов  в поступившем нам на проверку отзыве больше.\n",
    "\n",
    "\n",
    "Мы будем работать по заранее определённому пайплайну:\n",
    "\n",
    "1.  Сначала нам надо скачать дату -- соберите как минимум 60 (30 положительных  и 30 отрицательных) отзывов на похожие продукты (не надо мешать отзывы на отели с отзывами на ноутбуки) для составления \" тонального словаря\" (чем больше отзывов, тем лучше)  и 10 отзывов для проверки качества.   2 балла в случае сбора путём парсинга, 1 - если найдете уже готовые данные или просто закопипастите без парсинга\n",
    "\n",
    "2. Токенизируйте слова,  приведите их к нижнему регистру и к начальной форме  (1 балл за токенизацию, 1 - за начальную форму)\n",
    "\n",
    "3. Составьте 2 множества - в одном будут слова, которые встречаются только в положительных отзывах, а в другом - встречающиеся только в отрицательных. Попробуйте поиграть с частотностями и исключить шум (к примеру, выбросить слова, встречающиеся 1-2 раза) (3 балла) (если у вас получились пустые множества, уберите фильтр по частотности или увеличьте выборку)\n",
    "\n",
    "4. Создайте функцию, которая будет определять, положительный ли отзыв или отрицательный в зависимости от того, какие слова встретились в нём, и посчитайте качество при помощи accuracy (1  - за коректно работающую функцию, 1 - за подсчёт accuracy)\n",
    "\n",
    "5. Предложите как минимум 2 способа улучшить эту программу с помощью добавления к ней любых мулек  - просто словами, писать улучшающий код не надо (1 балл)\n",
    "\n",
    "6. Логичность и чистота кода (1 балл) \n",
    "\n",
    "Да, тут 11 баллов - один можно потерять.\n",
    "\n",
    "\n",
    "В случае, если после долгих мучений в п. 3 множества по объективным причинам не получается (покажите, что пытались) - отправляйте жабу - зачьтём полный балл"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Парсинг* и токенизация\n",
    "\n",
    "\\*К сожалению, вайлдберис не закрасивосупился, поэтому копипастила 35 положительных и 35 отрицательных со следующих сайтов:\n",
    "- [SYNERGETIC Гель для стирки универсальный](https://www.wildberries.ru/catalog/14792609/detail.aspx?targetUrl=XS)\n",
    "- [SYNERGETIC Гель для стирки детского белья](https://www.wildberries.ru/catalog/14792610/detail.aspx?targetUrl=XS)\n",
    "- [SYNERGETIC Кондиционер для белья \"Миндальное молочко\" ](https://www.wildberries.ru/catalog/14793781/detail.aspx?targetUrl=XS)\n",
    "- [SYNERGETIC Гель для стирки 2в1](https://www.wildberries.ru/catalog/27530245/detail.aspx?targetUrl=RG)\n",
    "\n",
    "Отзывы сохранены в файле posts.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/tasia/nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download(\"punkt\")\n",
    "# Не razel, поскольку не литературных текст с оч кривой пунктуацией"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Число положительных отзывов: 35\n",
      "Число отрицательных отзывов: 35\n"
     ]
    }
   ],
   "source": [
    "posts = {\"+\": [], \"-\": []}\n",
    "\n",
    "with open(\"posts.txt\", encoding='utf-8') as f:\n",
    "    for line in f:\n",
    "        tag = line[0]\n",
    "        post = [token for token in nltk.word_tokenize(line[2:-1].lower()) if token.isalpha()]\n",
    "        posts[tag].append(post)\n",
    "\n",
    "print(\"Число положительных отзывов:\", len(posts[\"+\"]))\n",
    "print(\"Число отрицательных отзывов:\", len(posts[\"-\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Создание множеств положительных и отрицательных слов"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Разделим на обучающую и тестовую выборки\n",
    "pos_train = posts[\"+\"][:29]\n",
    "neg_train = posts[\"-\"][:29]\n",
    "all_test = {\"+\": posts[\"+\"][30:], \"-\": posts[\"-\"][30:]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "pos_all_words = {word for post in pos_train for word in post}\n",
    "neg_all_words = {word for post in neg_train for word in post}\n",
    "same_words = pos_all_words & neg_all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Всего слов в положительных отзывах: 230\n",
      "Всего слов в отрицательных отзывах: 272\n",
      "Общих слов: 58\n"
     ]
    }
   ],
   "source": [
    "print(\"Всего слов в положительных отзывах:\", len(pos_all_words))\n",
    "print(\"Всего слов в отрицательных отзывах:\", len(neg_all_words))\n",
    "print(\"Общих слов:\", len(same_words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Осталось положительных: 172\n",
      "Осталось отрицательных: 214\n"
     ]
    }
   ],
   "source": [
    "pure_pos_words = pos_all_words - same_words\n",
    "pure_neg_words = neg_all_words - same_words\n",
    "print(\"Осталось положительных:\", len(pure_pos_words))\n",
    "print(\"Осталось отрицательных:\", len(pure_neg_words))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. Функция оценки тональности"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sentiment_analysis(post):\n",
    "    pos_count = 0\n",
    "    neg_count = 0\n",
    "    \n",
    "    for word in post:\n",
    "        if word in pure_pos_words:\n",
    "            pos_count += 1\n",
    "        elif word in pure_neg_words:\n",
    "            neg_count += 1\n",
    "            \n",
    "    if pos_count > neg_count:\n",
    "        return \"+\"\n",
    "    elif neg_count > pos_count:\n",
    "        return \"-\"\n",
    "    else:\n",
    "        return \"?\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Оценка качества\n",
    "\n",
    "Поскольку формально у меня получилась не бинарная классификация, то и классическое accuracy использовать нельзя. Поэтому дальше под accuracy я считала отношение правильно_размеченных к хоть_как-то_размеченным."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_pos_f_neg = 0 \n",
    "t_neg_f_pos = 0\n",
    "na = 0\n",
    "\n",
    "for tag in [\"+\", \"-\"]:\n",
    "    for post in all_test[tag]:\n",
    "        ans = sentiment_analysis(post)\n",
    "        if ans == \"?\":\n",
    "            na += 1\n",
    "        elif ans == tag:\n",
    "            t_pos_f_neg += 1\n",
    "        else:\n",
    "            t_neg_f_pos +=1   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 1.0\n",
      "Покрытие: 1.0\n"
     ]
    }
   ],
   "source": [
    "accuracy = t_pos_f_neg / (t_pos_f_neg + t_neg_f_pos)\n",
    "covered = (t_pos_f_neg + t_neg_f_pos) / (t_pos_f_neg + t_neg_f_pos + na)\n",
    "print(\"Accuracy:\", accuracy)\n",
    "print(\"Покрытие:\", covered)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Удивительно, но наш разметчик работает великолепно... Но, возможно, что просто тестовая выборка очень маленькая. Да и отзывы довольно однотипные в целом."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Идеи для улучшения\n",
    "\n",
    "- Лемматизировать или стеммизировать, чтобы 100500 *отлично*, *отличный* не различать\n",
    "- Не отделять отрицательные частицы от вершин\n",
    "- Считать по биграммам (расширенный вариант предыдущего улучшения)\n",
    "- Анализировать знаки препинания (скобочки, например)"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "authorship_tag": "ABX9TyOhO9ANVm4SXK9q5vI0e+E4",
   "collapsed_sections": [],
   "name": "Hometask 1.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
